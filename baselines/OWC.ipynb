{"cells":[{"cell_type":"code","execution_count":63,"metadata":{"executionInfo":{"elapsed":2060,"status":"ok","timestamp":1666315335175,"user":{"displayName":"Haochen Zhang","userId":"14248919892793833207"},"user_tz":240},"id":"U0TZ-BdDSu1l"},"outputs":[],"source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer\n","from nltk.stem import WordNetLemmatizer\n","import pandas as pd\n","import numpy as np\n","import string\n","import json\n","from sklearn.utils import shuffle"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# test cell\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":890,"status":"ok","timestamp":1666315336054,"user":{"displayName":"Haochen Zhang","userId":"14248919892793833207"},"user_tz":240},"id":"HKMfzrtF2ITT","outputId":"a7c0fdc7-5525-4100-abaa-684215921c98"},"outputs":[],"source":["# nltk downloads\n","nltk.download('stopwords')\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":66,"metadata":{"executionInfo":{"elapsed":718,"status":"ok","timestamp":1666315356984,"user":{"displayName":"Haochen Zhang","userId":"14248919892793833207"},"user_tz":240},"id":"P_r6SHVnJBuM"},"outputs":[],"source":["# Changed to load from json files\n","\n","all_path = \"../data/500QA.json\"\n","with open(all_path) as f:\n","  all_data = json.load(f)\n"]},{"cell_type":"markdown","metadata":{"id":"11xWVrPaUasf"},"source":["Stemming and stopword removal functions\n"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[],"source":["lemmatizer = WordNetLemmatizer()\n","stop = set(stopwords.words('english') + list(string.punctuation))\n","\n","def clean_text(text):\n","  lst_tokens = [i for i in word_tokenize(text.lower()) if i not in stop]\n","  lemmatized_lst = []\n","  for token in lst_tokens:\n","    lemmatized_token = lemmatizer.lemmatize(token)\n","    lemmatized_lst.append(lemmatized_token)\n","  lemmatized_sentence = \" \".join(lemmatized_lst)\n","  return lemmatized_sentence"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[],"source":["all_descriptions = []\n","queries = []\n","for d in all_data:\n","  queries.append(d[\"query\"])\n","  d[\"query\"] = clean_text(d[\"query\"])\n","  for o in d[\"options\"]:\n","    d[\"options\"][o] = clean_text(d[\"options\"][o])\n","    all_descriptions += d[\"options\"][o]\n","\n","descriptions = all_descriptions"]},{"cell_type":"markdown","metadata":{"id":"gzdMTJAUVSaV"},"source":["Choose correct option based on highest word overlap between query and description"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[],"source":["# test cell\n","\n","# Helper function to find number of overlapping words between two sentences\n","def calc_overlap(s1, s2):\n","  s1_list = s1.split(' ')\n","  s2_list = s2.split(' ')\n","  return len(list(set(s1_list)&set(s2_list)))\n","\n","# General function to determine correct answer based on word overlap after pre-processing\n","def word_overlap(data, name):\n","  results = []\n","  correct = 0\n","  total = len(data)\n","  type_correct = {\n","    \"Specific\": 0,\n","    \"Subjective\": 0,\n","    \"Indirect\": 0,\n","    \"Compound\": 0,\n","    \"Negated\": 0,\n","    \"Analogical\": 0,\n","    \"Temporal\": 0}\n","    \n","  for d in data:\n","    try:\n","      options = [val for val in d['options'].values()]\n","      query = d['query']\n","      answer = d['options'][d['answer']]\n","    except:\n","      continue\n","    \n","    options_str = [str(i) for i in options]\n","    cleaned_query = str(query)\n","    \n","    overlap = []\n","    for option in options_str:\n","      cleaned_option = option\n","      num_overlap = calc_overlap(cleaned_query, cleaned_option)\n","      overlap.append(num_overlap)\n","    \n","    overlap, options = shuffle(overlap, options, random_state=0)\n","    # Ties in argmax are broken by picking first element\n","    ind = np.argmax(overlap) \n","    result = 0\n","    if (options[ind]) == answer:\n","      correct += 1\n","      result = 1\n","      for key in d['query_type']:\n","        if d['query_type'][key] == 1:\n","          type_correct[key] += 1\n","    #results.append([result, \"Query: \" + query, \"Recommended: \" + str(options[ind])])\n","  print(\"Results for {}:\".format(name))\n","  print(\"Total correct answers: {} out of {}\".format(correct, total))\n","  #print(results)\n","  print(type_correct)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1497,"status":"ok","timestamp":1666315358636,"user":{"displayName":"Haochen Zhang","userId":"14248919892793833207"},"user_tz":240},"id":"CdKd7064LpPz","outputId":"1c4fec8c-a72f-47de-d17b-2013e6861a71"},"outputs":[],"source":["word_overlap(all_data, \"all\")"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.7.3 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"vscode":{"interpreter":{"hash":"16a4e7ece9e04ef6782fa5b68100d2dbb77b79a687737e3689cfa4e040872a6d"}}},"nbformat":4,"nbformat_minor":0}
