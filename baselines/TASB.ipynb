{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA7E2CCtLwp9",
        "outputId": "ad507149-abaa-4d4f-b2c3-2f6bbe43c033"
      },
      "outputs": [],
      "source": [
        "pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "XdzOY8GlOfaR"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "import torch\n",
        "import json\n",
        "from sklearn.utils import shuffle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JwyxPkQKMb71"
      },
      "outputs": [],
      "source": [
        "#path = \"../../data/data.json\" # will be changed to suit data path later\n",
        "#dataset = json.load(path)\n",
        "\n",
        "with open(\"y.json\", 'r', encoding='utf-8') as f:\n",
        " data = json.load(f)\n",
        "#path =  # will be changed to suit data path later\n",
        "dataset = data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlfEpYMtYpIE"
      },
      "source": [
        "1. Define a **NeuralEmbedder** class to abstract away the embedding process for the retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1DwCjX6mL6VQ"
      },
      "outputs": [],
      "source": [
        "class NeuralEmbedder():\n",
        "  def __init__(self, model_name, tokenizer_name):\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(model_name) \n",
        "    self.bert_model = AutoModel.from_pretrained(tokenizer_name)\n",
        "  def embed(self,text):\n",
        "    return self.bert_model(**self.tokenizer(text,return_tensors=\"pt\"))[0][:,0,:].squeeze(0).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLuHKcgMY4Zn"
      },
      "source": [
        "2. Define **the search engine** class. We embedded the documents once and saved the representations in a numpy matrix so we would not have to compute them repeatedly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ncaN09bhL7E2"
      },
      "outputs": [],
      "source": [
        "class NeuralSearchEngine():\n",
        "\n",
        "  def __init__(self, embedder):\n",
        "    self.embedder = embedder\n",
        "\n",
        "  def index(self, documents):\n",
        "    self.documents = documents\n",
        "    encoded_docs = []\n",
        "    for d in documents:\n",
        "      with torch.no_grad():\n",
        "        d_encoded = self.embedder.embed(d)\n",
        "      encoded_docs.append(d_encoded.reshape(-1,768))\n",
        "    self.index = np.concatenate(encoded_docs,axis=0)\n",
        "  \n",
        "  def search(self, query):\n",
        "    with torch.no_grad():\n",
        "      q_encoded = self.embedder.embed(query).reshape(-1,768)\n",
        "    scores = q_encoded.dot(self.index.T)[0]\n",
        "\n",
        "    scores = shuffle(scores, random_state = 0)\n",
        "    args = np.argsort(scores)[::-1]\n",
        "\n",
        "    print(\"\\nThe query:\", query,\"\\nTop three:\")\n",
        "\n",
        "    predicted = \"\"\n",
        "    for i in range(3):\n",
        "      print((i+1),'-','Score:',scores[args[i]],'doc:',self.documents[args[i]])\n",
        "      if i == 0:\n",
        "        predicted = self.documents[args[i]]\n",
        "       \n",
        "    return predicted\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oK4f60ua5Ry"
      },
      "source": [
        "Main function to score from TASB and choose option"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5quk-wrba404",
        "outputId": "8a041170-79c5-4b5c-87b9-101a6d28ab17"
      },
      "outputs": [],
      "source": [
        "def tasb_score(dataset):\n",
        "  # number of correct predictions\n",
        "  correct = 0\n",
        "  # h@1 evaluation metric\n",
        "  total_hit_at_1 = 0\n",
        "  # number of queries\n",
        "  count = 0\n",
        "\n",
        "  # create an embedder object the tokenizer and model \n",
        "  embedder = NeuralEmbedder(\"sebastian-hofstaetter/distilbert-dot-tas_b-b256-msmarco\",\"sebastian-hofstaetter/distilbert-dot-tas_b-b256-msmarco\")\n",
        "\n",
        "  # loop through each query\n",
        "  for query in dataset:\n",
        "    count +=1\n",
        "    print(count)\n",
        "\n",
        "    docs = []\n",
        "    for description in query[\"options\"].values():\n",
        "      docs.append(description)\n",
        "\n",
        "    # create a search engine object for this query \n",
        "    engine = NeuralSearchEngine(embedder)\n",
        "    # index the options into the search engine\n",
        "    engine.index(docs)\n",
        "\n",
        "    # check if model predicted the correct answer\n",
        "    ## get the predicted description\n",
        "    predicted_description = engine.search(query[\"query\"])\n",
        "    print(\"predicted: \"+predicted_description)\n",
        "    ## loop through all correct options to find the predicted id\n",
        "    for option in query[\"options\"]:\n",
        "      print(\"option: \"+query[\"options\"][option])\n",
        "      print(\"id: \"+option)\n",
        "      if query[\"options\"][option] == predicted_description:\n",
        "        predicted_id = option\n",
        "\n",
        "    ## check if predicted id is the same as correct id\n",
        "    if predicted_id == query[\"answer\"]:\n",
        "      print(True, \": The correct description has the highest score.\",\"\\n\")\n",
        "      correct += 1\n",
        "      total_hit_at_1 += 1\n",
        "    else:\n",
        "      print(False, \": The correct description is:\", (query[\"options\"][query[\"answer\"]]),\"\\n\")\n",
        "      \n",
        "  print(\"Total correct =\", correct)\n",
        "  print(\"average h@1\",total_hit_at_1/count)\n",
        "\n",
        "tasb_score(dataset)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "TASB.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
